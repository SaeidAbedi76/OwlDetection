{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a176aaa3-bf3b-4a8e-af30-0e06802ed9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.8.0+cu111 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (1.8.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.9.0+cu111 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (0.9.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.8.0 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: typing-extensions in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from torch==1.8.0+cu111) (4.5.0)\n",
      "Requirement already satisfied: numpy in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from torch==1.8.0+cu111) (1.24.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from torchvision==0.9.0+cu111) (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "# prompt: need to install pytorch 1.7.1+ cu110\n",
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install torch==1.11.0+cu102 torchvision==0.12.0+cu102 torchaudio==0.11.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991188c6-2d17-4451-8be2-ff7603ba0bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.8.0+cu111\n",
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecb2e6b-6e79-40e4-934b-43264a4c9cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner==1.4.7 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner==1.4.7) (2.13.1)\n",
      "Requirement already satisfied: packaging in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner==1.4.7) (23.2)\n",
      "Requirement already satisfied: requests in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner==1.4.7) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner==1.4.7) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner==1.4.7) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner==1.4.7) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner==1.4.7) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner==1.4.7) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner==1.4.7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e04348eb-3010-4654-9129-39465a25e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  7 23:22:20 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   43C    P8    11W / 450W |   1539MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1769      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A    205723      G   /usr/lib/xorg/Xorg               1382MiB |\n",
      "|    0   N/A  N/A    205851      G   /usr/bin/gnome-shell               63MiB |\n",
      "|    0   N/A  N/A   2234180      G   /usr/lib/firefox/firefox           14MiB |\n",
      "|    0   N/A  N/A   3709727      G   ...RendererForSitePerProcess       14MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48c4e797-dda0-4b63-8d39-1fb54c027685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner) (2.13.1)\n",
      "Requirement already satisfied: packaging in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/islamsa/anaconda3/envs/sam_hq/lib/python3.8/site-packages (from requests->keras-tuner) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7418c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 01s]\n",
      "val_accuracy: 0.2666666805744171\n",
      "\n",
      "Best val_accuracy So Far: 0.6666666865348816\n",
      "Total elapsed time: 00h 10m 55s\n",
      "The optimal number of layers is 2.\n",
      "The optimal filters per layer are 32, 32.\n",
      "The optimal activation functions per layer are relu, relu.\n",
      "The optimal learning rate for the optimizer is 0.0005.\n",
      "The optimal optimizer is adam.\n",
      "{'num_layers': 2, 'filters_0': 32, 'activation_0': 'relu', 'filters_1': 32, 'activation_1': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner import HyperModel, HyperParameters, Tuner\n",
    "from keras_tuner.tuners import GridSearch\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# Set up image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Set up the directories\n",
    "train_dir = '/home/islamsa/Documents/OwlDetection/train'\n",
    "validation_dir = '/home/islamsa/Documents/OwlDetection/valid'\n",
    "test_dir = '/home/islamsa/Documents/OwlDetection/test'\n",
    "\n",
    "# Data augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Note: validation and test data should not be augmented\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, img_height, img_width, num_classes):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Optimizing the number of convolutional layers\n",
    "        for i in range(hp.Int('num_layers', 2, 4)):  # Number of layers is between 2 and 4\n",
    "            model.add(Conv2D(hp.Choice(f'filters_{i}', [32, 64, 128, 256]),\n",
    "                             (3, 3), padding='same',\n",
    "                             input_shape=(self.img_height, self.img_width, 3)))\n",
    "            model.add(Activation(hp.Choice(f'activation_{i}', ['relu', 'sigmoid', 'tanh'])))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, kernel_regularizer=regularizers.l2(0.01)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Tuner for optimizer\n",
    "        hp_optimizer = hp.Choice('optimizer', ['adam', 'adadelta', 'adamax'])\n",
    "        if hp_optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001, 0.00001]))\n",
    "        elif hp_optimizer == 'adadelta':\n",
    "            optimizer = Adadelta(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001, 0.00001]))\n",
    "        else:  # hp_optimizer == 'adamax'\n",
    "            optimizer = Adamax(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001, 0.00001]))\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = MyHyperModel(img_height, img_width, num_classes)\n",
    "\n",
    "tuner = GridSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Adjust number of trials\n",
    "    executions_per_trial=1,\n",
    "    directory='/home/islamsa/Documents/OwlDetection/hyperparameter_tuning',\n",
    "    project_name='owl_detection_tuning'\n",
    ")\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Start search\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping],  # Early stopping callback\n",
    "    verbose=1  # Detailed logs for each trial\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(f\"The optimal number of layers is {best_hps.get('num_layers')}.\")\n",
    "print(f\"The optimal filters per layer are {', '.join(str(best_hps.get(f'filters_{i}')) for i in range(best_hps.get('num_layers')))}.\")\n",
    "\n",
    "# Check if each layer exists before accessing its activation function\n",
    "activations = []\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    activation_i = best_hps.get(f'activation_{i}')\n",
    "    if activation_i is not None:\n",
    "        activations.append(activation_i)\n",
    "print(f\"The optimal activation functions per layer are {', '.join(activations)}.\")\n",
    "\n",
    "print(f\"The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\")\n",
    "\n",
    "print(f\"The optimal optimizer is {best_hps.get('optimizer')}.\")\n",
    "print(best_hps.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4dba087-ae69-4d72-8e24-eef6a1147952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 15m 26s]\n",
      "val_loss: 6.579392910003662\n",
      "\n",
      "Best val_loss So Far: 1.1059889793395996\n",
      "Total elapsed time: 01h 00m 36s\n",
      "The optimal number of layers is 2.\n",
      "The optimal filters per layer are 32, 32.\n",
      "The optimal activation functions per layer are relu, relu.\n",
      "The optimal learning rate for the optimizer is 0.0005.\n",
      "The optimal optimizer is adam.\n",
      "{'num_layers': 2, 'filters_0': 32, 'activation_0': 'relu', 'filters_1': 32, 'activation_1': 'relu', 'optimizer': 'adam', 'learning_rate': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner import HyperModel, HyperParameters, Tuner\n",
    "from keras_tuner.tuners import GridSearch\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# Set up image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Set up the directories\n",
    "train_dir = '/home/islamsa/Documents/OwlDetection/train'\n",
    "validation_dir = '/home/islamsa/Documents/OwlDetection/valid'\n",
    "test_dir = '/home/islamsa/Documents/OwlDetection/test'\n",
    "\n",
    "# Data augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Note: validation and test data should not be augmented\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical',\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, img_height, img_width, num_classes):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Optimizing the number of convolutional layers\n",
    "        for i in range(hp.Int('num_layers', 2, 4)):  # Number of layers is between 2 and 4\n",
    "            model.add(Conv2D(hp.Choice(f'filters_{i}', [32, 64, 128, 256]),\n",
    "                             (3, 3), padding='same',\n",
    "                             input_shape=(self.img_height, self.img_width, 3)))\n",
    "            model.add(Activation(hp.Choice(f'activation_{i}', ['relu', 'sigmoid', 'tanh'])))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, kernel_regularizer=regularizers.l2(0.01)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Tuner for optimizer\n",
    "        hp_optimizer = hp.Choice('optimizer', ['adam', 'adadelta', 'adamax'])\n",
    "        if hp_optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001, 0.00001]))\n",
    "        elif hp_optimizer == 'adadelta':\n",
    "            optimizer = Adadelta(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001, 0.00001]))\n",
    "        else:  # hp_optimizer == 'adamax'\n",
    "            optimizer = Adamax(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001, 0.00001]))\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = MyHyperModel(img_height, img_width, num_classes)\n",
    "\n",
    "tuner = GridSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,  # Adjust number of trials\n",
    "    executions_per_trial=1,\n",
    "    directory='/home/islamsa/Documents/OwlDetection/hyperparameter_tuning_val_loss',\n",
    "    project_name='owl_detection_tuning'\n",
    ")\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Start search\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    epochs=150,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping],  # Early stopping callback\n",
    "    verbose=1  # Detailed logs for each trial\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(f\"The optimal number of layers is {best_hps.get('num_layers')}.\")\n",
    "print(f\"The optimal filters per layer are {', '.join(str(best_hps.get(f'filters_{i}')) for i in range(best_hps.get('num_layers')))}.\")\n",
    "\n",
    "# Check if each layer exists before accessing its activation function\n",
    "activations = []\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    activation_i = best_hps.get(f'activation_{i}')\n",
    "    if activation_i is not None:\n",
    "        activations.append(activation_i)\n",
    "print(f\"The optimal activation functions per layer are {', '.join(activations)}.\")\n",
    "\n",
    "print(f\"The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\")\n",
    "\n",
    "print(f\"The optimal optimizer is {best_hps.get('optimizer')}.\")\n",
    "print(best_hps.values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4de53-7d61-4e6f-a984-22c385c511d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
